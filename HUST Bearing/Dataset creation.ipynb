{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048560, 8)\n",
      "(1048560, 8)\n",
      "(1048560, 8)\n",
      "(1048560, 8)\n",
      "(1048560, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.117462</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>-0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.122317</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>-0.004050</td>\n",
       "      <td>-0.006717</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>-0.012211</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>-0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.121311</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>-0.007553</td>\n",
       "      <td>0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.120751</td>\n",
       "      <td>-0.007136</td>\n",
       "      <td>-0.002774</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.117236</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>-0.007696</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.005544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1   Column2   Column3   Column4   Column5   Column6   Column7   \n",
       "0 -0.117462 -0.001712  0.001460  0.007768  0.002619  0.003544  0.003097  \\\n",
       "1 -0.122317 -0.000914 -0.004050 -0.006717  0.003122 -0.012211  0.005323   \n",
       "2 -0.121311  0.004437  0.003101  0.007753  0.006050  0.003830 -0.007553   \n",
       "3 -0.120751 -0.007136 -0.002774  0.002573  0.006198  0.001988 -0.001854   \n",
       "4 -0.117236 -0.000008  0.000765 -0.007696  0.002301  0.004705  0.000281   \n",
       "\n",
       "    Column8  \n",
       "0 -0.007119  \n",
       "1 -0.002731  \n",
       "2  0.008774  \n",
       "3  0.002958  \n",
       "4  0.005544  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "# 1.读取数据\n",
    "data_file_csv1 = 'inner_20_0_new.csv'\n",
    "data_file_csv2 = 'ball_20_0_new.csv'\n",
    "data_file_csv3 = 'outer_20_0_new.csv'\n",
    "data_file_csv4 = 'comb_20_0_new.csv'\n",
    "data_file_csv5 = 'health_20_0_new.csv'\n",
    "origin_data1 = pd.read_csv(data_file_csv1)\n",
    "origin_data2 = pd.read_csv(data_file_csv2)\n",
    "origin_data3 = pd.read_csv(data_file_csv3)\n",
    "origin_data4 = pd.read_csv(data_file_csv4)\n",
    "origin_data5 = pd.read_csv(data_file_csv5)\n",
    "\n",
    "print(origin_data1.shape)\n",
    "print(origin_data2.shape)\n",
    "print(origin_data3.shape)\n",
    "print(origin_data4.shape)\n",
    "print(origin_data5.shape)\n",
    "origin_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048560, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inner</th>\n",
       "      <th>ball</th>\n",
       "      <th>outer</th>\n",
       "      <th>comb</th>\n",
       "      <th>health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001460</td>\n",
       "      <td>-0.007886</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.392166</td>\n",
       "      <td>-0.458107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004050</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>-0.379996</td>\n",
       "      <td>-0.449544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003101</td>\n",
       "      <td>-0.002126</td>\n",
       "      <td>-0.000834</td>\n",
       "      <td>-0.389422</td>\n",
       "      <td>-0.454772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002774</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.388949</td>\n",
       "      <td>-0.458454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-0.386126</td>\n",
       "      <td>-0.450946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048555</th>\n",
       "      <td>-0.001255</td>\n",
       "      <td>-0.005304</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>-0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048556</th>\n",
       "      <td>-0.003281</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048557</th>\n",
       "      <td>0.003114</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048558</th>\n",
       "      <td>-0.007981</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>-0.004952</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048559</th>\n",
       "      <td>0.006745</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>-0.001630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048560 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            inner      ball     outer      comb    health\n",
       "0        0.001460 -0.007886 -0.000808 -0.392166 -0.458107\n",
       "1       -0.004050  0.003791  0.002338 -0.379996 -0.449544\n",
       "2        0.003101 -0.002126 -0.000834 -0.389422 -0.454772\n",
       "3       -0.002774 -0.001577  0.001218 -0.388949 -0.458454\n",
       "4        0.000765  0.002419  0.000473 -0.386126 -0.450946\n",
       "...           ...       ...       ...       ...       ...\n",
       "1048555 -0.001255 -0.005304  0.003202  0.003767 -0.002427\n",
       "1048556 -0.003281  0.002497 -0.001090  0.000229  0.000675\n",
       "1048557  0.003114 -0.001674  0.003688  0.000527  0.004184\n",
       "1048558 -0.007981  0.008260 -0.004952  0.000223  0.000635\n",
       "1048559  0.006745 -0.001767  0.001504  0.001041 -0.001630\n",
       "\n",
       "[1048560 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用驱动端数据\n",
    "data_column = 'Column3'\n",
    "columns_name = ['inner','ball','outer','comb','health']\n",
    "file_names = ['inner_20_0_new.csv', 'ball_20_0_new.csv', 'outer_20_0_new.csv', 'comb_20_0_new.csv', 'health_20_0_new.csv']\n",
    "combine_data = pd.DataFrame()\n",
    "for index in range(5):\n",
    "    # 读取 CSV 文件\n",
    "    data = pd.read_csv(file_names[index])\n",
    "    dataList = data[data_column]\n",
    "    combine_data[columns_name[index]] = dataList\n",
    "print(combine_data.shape)\n",
    "combine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048560, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_data.set_index('inner',inplace=True)\n",
    "combine_data.to_csv('combine_data.csv')\n",
    "combine_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于上述表格数据，要重新制作数据集，制作思路：\n",
    "1. 对于上述表格每一列 数据，重新采样 信号长度为1024，滑动窗重叠率为0.5\n",
    "2. 然后把重新采样的信号数据 放在另外的表格中，一行对应一个信号，而且在末尾添加分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_set']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from joblib import dump, load\n",
    "\n",
    "# 时间步长 1024 和 重叠率 -0.5 \n",
    "# window = 1024  step = 512  \n",
    "\n",
    "def split_data_with_overlap(data, time_steps, lable, overlap_ratio=0.5):\n",
    "    \"\"\"\n",
    "        data:要切分的时间序列数据,可以是一个一维数组或列表。\n",
    "        time_steps:切分的时间步长,表示每个样本包含的连续时间步数。\n",
    "        lable: 表示切分数据对应 类别标签\n",
    "        overlap_ratio:前后帧切分时的重叠率,取值范围为 0 到 1,表示重叠的比例。\n",
    "    \"\"\"\n",
    "    stride = int(time_steps * (1 - overlap_ratio))  # 计算步幅\n",
    "    samples = (len(data) - time_steps) // stride + 1  # 计算样本数\n",
    "    # 用于存储生成的数据\n",
    "    Clasiffy_dataFrame = pd.DataFrame(columns=[x for x in range(time_steps + 1)])  \n",
    "    data_list = []\n",
    "    for i in range(samples):\n",
    "        start_idx = i * stride\n",
    "        end_idx = start_idx + time_steps\n",
    "        temp_data = data[start_idx:end_idx].tolist()\n",
    "        temp_data.append(lable)  # 对应哪一类\n",
    "        data_list.append(temp_data)\n",
    "    Clasiffy_dataFrame = pd.DataFrame(data_list, columns=Clasiffy_dataFrame.columns)\n",
    "    return Clasiffy_dataFrame\n",
    "\n",
    "# 归一化数据\n",
    "def normalize(data):\n",
    "    ''' (0,1)归一化\n",
    "        参数:一维时间序列数据\n",
    "    '''\n",
    "    s= (data-min(data)) / (max(data)-min(data))\n",
    "    return  s\n",
    "\n",
    "# 数据集的制作\n",
    "def make_datasets(data_file_csv, split_rate = [0.7,0.2,0.1]):\n",
    "    '''\n",
    "        参数:\n",
    "        data_file_csv: 故障分类的数据集,csv格式,数据形状: 119808行  10列\n",
    "        label_list: 故障分类标签\n",
    "        split_rate: 训练集、验证集、测试集划分比例\n",
    "\n",
    "        返回:\n",
    "        train_set: 训练集数据\n",
    "        val_set: 验证集数据\n",
    "        test_set: 测试集数据\n",
    "    '''\n",
    "    # 1.读取数据\n",
    "    origin_data = pd.read_csv(data_file_csv)\n",
    "    # 2.分割样本点\n",
    "    time_steps = 1024  # 时间步长\n",
    "    overlap_ratio = 0.5  # 重叠率\n",
    "    # 用于存储生成的数据# 10个样本集合\n",
    "    samples_data = pd.DataFrame(columns=[x for x in range(time_steps + 1)])  \n",
    "    # 记录类别标签\n",
    "    label = 0\n",
    "    # 使用iteritems()方法遍历每一列\n",
    "    for column_name, column_data in origin_data.items():\n",
    "        # 对数据集的每一维进行归一化\n",
    "        # column_data = normalize(column_data)\n",
    "        # 划分样本点  window = 1024  overlap_ratio = 0.5 \n",
    "        split_data = split_data_with_overlap(column_data, time_steps, label, overlap_ratio)\n",
    "        label += 1 # 类别标签递增\n",
    "        samples_data = pd.concat([samples_data, split_data])\n",
    "    # 随机打乱样本点顺序 \n",
    "    # 打乱索引并重置索引\n",
    "    samples_data = samples_data.sample(frac=1).reset_index(drop=True)\n",
    "    # 3.分割训练集-、验证集、测试集\n",
    "    sample_len = len(samples_data) # 每一类样本数量\n",
    "    train_len = int(sample_len*split_rate[0])  # 向下取整\n",
    "    val_len = int(sample_len*split_rate[1]) \n",
    "    train_set = samples_data.iloc[0:train_len,:]   \n",
    "    val_set = samples_data.iloc[train_len:train_len+val_len,:]   \n",
    "    test_set = samples_data.iloc[train_len+val_len:,:]   \n",
    "    return  train_set, val_set, test_set, samples_data\n",
    "\n",
    "# 生成数据集\n",
    "train_set, val_set, test_set, samples_data = make_datasets('combine_data.csv')\n",
    "\n",
    "# 保存数据\n",
    "dump(train_set, 'train_set') \n",
    "dump(val_set, 'val_set') \n",
    "dump(test_set, 'test_set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10230, 1024)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(samples_data))\n",
    "samples_data.set_index(0, inplace=True)\n",
    "samples_data.to_csv('samples_data.csv')\n",
    "samples_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10230, 1025)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_ylabel']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 制作数据集和标签\n",
    "import torch\n",
    "\n",
    "# 这些转换是为了将数据和标签从Pandas数据结构转换为PyTorch可以处理的张量，\n",
    "# 以便在神经网络中进行训练和预测。\n",
    "\n",
    "def make_data_labels(dataframe):\n",
    "    '''\n",
    "        参数 dataframe: 数据框\n",
    "        返回 x_data: 数据集     torch.tensor\n",
    "            y_label: 对应标签值  torch.tensor\n",
    "    '''\n",
    "    # 信号值\n",
    "    x_data = dataframe.iloc[:,0:-1]\n",
    "    # 标签值\n",
    "    y_label = dataframe.iloc[:,-1]\n",
    "    x_data = torch.tensor(x_data.values).float()\n",
    "    y_label = torch.tensor(y_label.values.astype('int64')) # 指定了这些张量的数据类型为64位整数，通常用于分类任务的类别标签\n",
    "    return x_data, y_label\n",
    "\n",
    "# 加载数据\n",
    "train_set = load('train_set') \n",
    "val_set = load('val_set') \n",
    "test_set = load('test_set') \n",
    "\n",
    "# 制作标签\n",
    "train_xdata, train_ylabel = make_data_labels(train_set)\n",
    "val_xdata, val_ylabel = make_data_labels(val_set)\n",
    "test_xdata, test_ylabel = make_data_labels(test_set)\n",
    "# 保存数据\n",
    "dump(train_xdata, 'train_xdata')\n",
    "dump(val_xdata, 'val_xdata')\n",
    "dump(test_xdata, 'test_xdata')\n",
    "dump(train_ylabel, 'train_ylabel')\n",
    "dump(val_ylabel, 'val_ylabel')\n",
    "dump(test_ylabel, 'test_ylabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据 形状：\n",
      "torch.Size([7161, 1024]) torch.Size([7161])\n",
      "torch.Size([2046, 1024]) torch.Size([2046])\n",
      "torch.Size([1023, 1024]) torch.Size([1023])\n"
     ]
    }
   ],
   "source": [
    "print('数据 形状：')\n",
    "print(train_xdata.size(), train_ylabel.size())\n",
    "print(val_xdata.size(), val_ylabel.size())\n",
    "print(test_xdata.size(), test_ylabel.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
